{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc394a07-c378-49aa-ac8d-6fa57cb6b808",
   "metadata": {},
   "source": [
    "#  HYPERPARAMETER OPTIMIZATION AND BENCHMARK TESTING\n",
    "\n",
    "Leveraging the stability-selected feature subsets identified in the previous module, this notebook focuses on the training and fine-tuning of our three candidate classifiers.\n",
    "\n",
    "The objective is to find the optimal hyperparameter configuration for each model to maximize the Matthews Correlation Coefficient (MCC) on the Development Set (5-Fold CV), ensuring robustness against class imbalance before the final evaluation on the unseen Benchmark Set.\n",
    "\n",
    "**Workflow for this module:**\n",
    "\n",
    "1.  **Data Preparation and Validation Strategy**: We load the three distinct feature signatures (Tree-specific, SVM-specific, and Linear-specific) serialized in the previous step. We rigorously respect the data split: the Development Set (Set 1,2,3,4,5) is used exclusively for cross-validation and hyperparameter tuning, while the Benchmark Set remains completely unseen until the final inference step, acting as a proxy for real-world deployment.\n",
    "\n",
    "2.  **Tree-based Model Optimization (Balanced Random Forest)**: Using the tree-specific feature set, we employ Bayesian Optimization to explore the hyperparameter space efficiently. We tune critical parameters such as `n_estimators`, `max_depth`, and splitting criteria (`min_samples_leaf`) to balance the model's complexity and prevent overfitting, maximizing the MCC score.\n",
    "\n",
    "3.  **Kernel-based Model Optimization (SVM)**: For the Support Vector Machine, we utilize the specific subset of  features identified by the RBF-Kernel stability selection. The Bayesian search focuses on optimizing the regularization parameter `C` and the kernel coefficient `gamma`, searching for the ideal non-linear decision boundary that separates the disease stages in the high-dimensional feature space.\n",
    "\n",
    "4.  **Linear Model Optimization (Logistic Regression)**: We perform optimization on the Logistic Regression model using its specific feature set. We tune the inverse regularization strength `C` to control the penalty on the coefficients. This serves as our robust linear baseline to determine if the added complexity of non-linear models (RF and SVM) translates into a statistically significant performance gain.\n",
    "\n",
    "5.  **Final Inference and Artifact Serialization**: Once the optimal hyperparameters are identified, each model will generate prediction vectors for the Benchmark Set. These predictions, along with the trained model objects, are serialized (`.pkl` files) to be passed to the next module (`04_Analysis_Results.ipynb`) for the final comparative analysis, confusion matrix visualization, and clinical interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "768cc93e-e13b-4aaf-aa7d-b096d704060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#! pip install scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef , confusion_matrix, classification_report\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276acfa9-fb16-487f-be04-c0bbd68af935",
   "metadata": {},
   "source": [
    "## 1.  Data Preparation and Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc2db3f-fe17-440d-9848-a43d70179c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "features_to_use_tree = joblib.load('../data/best_features_list_tree.pkl')\n",
    "features_to_use_svm = joblib.load('../data/best_features_list_svm.pkl')\n",
    "features_to_use_lr = joblib.load('../data/best_features_list_lr.pkl')\n",
    "df=pd.read_csv(\"../data/data_refined_stratifkfold.csv\")\n",
    "x_trainval,y_trainval=df.query(\"Set=='1' or Set=='2' or Set=='3' or Set=='4' or Set=='5'\").drop(columns=['Set','Stage']),df.query(\"Set=='1' or Set=='2' or Set=='3' or Set=='4' or Set=='5'\")['Stage']\n",
    "x_bench,y_bench=df.query(\"Set=='Benchmark'\").drop(columns=['Set','Stage']),df.query(\"Set=='Benchmark'\")['Stage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc07caf-e7cf-4abc-8b16-5521be57143e",
   "metadata": {},
   "source": [
    "## 2. Tree-based Model Optimization (Balanced Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c14ead-d4ce-4372-b92b-be1ced3cd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Best parameters found:] \n",
      "OrderedDict({'rf__max_depth': 81, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 7, 'rf__min_samples_split': 2, 'rf__n_estimators': 677})\n",
      "[Best MCC validation] 0.2538\n"
     ]
    }
   ],
   "source": [
    "x_trainval_tree=x_trainval[features_to_use_tree]\n",
    "x_bench_tree=x_bench[features_to_use_tree]\n",
    "pipeline_tree = Pipeline([(\"rf\", BalancedRandomForestClassifier(sampling_strategy='all', replacement=True, random_state=42, n_jobs=-1))])\n",
    "search_space_tree = {\n",
    "    \"rf__n_estimators\": Integer(100, 1000),      # Number of trees\n",
    "    \"rf__max_depth\": Integer(10, 100),           # maximum deep, to avoid overfitting\n",
    "    \"rf__min_samples_split\": Integer(2, 20),     # minimum number of samples on each split\n",
    "    \"rf__min_samples_leaf\": Integer(1, 10),      # Minimum number of samples on each leaf\n",
    "    \"rf__max_features\": Categorical(['sqrt', 'log2']) # how many features in each split\n",
    "}\n",
    "\n",
    "bayes_tree = BayesSearchCV(\n",
    "    estimator=pipeline_tree,\n",
    "    search_spaces=search_space_tree,\n",
    "    scoring=\"matthews_corrcoef\",   \n",
    "    n_jobs=-1,\n",
    "    refit=False,                 \n",
    "    random_state=42,\n",
    "    cv=5,\n",
    "    n_iter=100 \n",
    ")\n",
    "\n",
    "bayes_tree.fit(x_trainval_tree, y_trainval)\n",
    "\n",
    "print(\"\\n[Best parameters found:] \")\n",
    "print(bayes_tree.best_params_)\n",
    "print(f\"[Best MCC validation] {bayes_tree.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd73dae7-7e21-4016-ab9b-ea53a003d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC on testing set (bayesian search): 0.19601429225839503\n"
     ]
    }
   ],
   "source": [
    "#predict the benchmark set\n",
    "pipeline_tree.set_params(**bayes_tree.best_params_).fit(x_trainval_tree, y_trainval) #parameters of BayesSearchCV\n",
    "bench_pred_tree = pipeline_tree.predict(x_bench_tree)\n",
    "#save the model\n",
    "with open(\"../models/tree_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(pipeline_tree, f)\n",
    "#compute the mcc\n",
    "mcc_bayes_tree = matthews_corrcoef(y_bench , bench_pred_tree)\n",
    "print(f\"MCC on testing set (bayesian search): {mcc_bayes_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91afd307-7503-486c-9e9e-b28766bae2a5",
   "metadata": {},
   "source": [
    "## 3. Kernel-based Model Optimization (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efa2737-81bb-45fc-a696-94655839b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Best parameters found:] \n",
      "OrderedDict({'svm__C': 8.890674932384222, 'svm__gamma': 0.015527855782441872, 'svm__kernel': 'rbf'})\n",
      "[Best MCC validation] 0.3301\n"
     ]
    }
   ],
   "source": [
    "x_trainval_svm=x_trainval[features_to_use_svm]\n",
    "x_bench_svm=x_bench[features_to_use_svm]\n",
    "\n",
    "pipeline_svm = Pipeline([(\"svm\" , SVC(cache_size=1500,class_weight='balanced'))])\n",
    "search_space_svm = {\n",
    "        \"svm__kernel\": Categorical([\"rbf\"]),\n",
    "        \"svm__C\": Real(0.01, 1000, prior=\"log-uniform\"),                \n",
    "        \"svm__gamma\": Real(1e-5, 100, prior=\"log-uniform\"), \n",
    "    }\n",
    "#set up the BayesSearch\n",
    "bayes_svm = BayesSearchCV(\n",
    "    estimator=pipeline_svm,\n",
    "    search_spaces=search_space_svm,\n",
    "    scoring=\"matthews_corrcoef\",   \n",
    "    n_jobs=-1,\n",
    "    refit=False,                 \n",
    "    random_state=42,\n",
    "    cv=5,\n",
    "    n_iter=100\n",
    ")\n",
    "bayes_svm.fit(x_trainval_svm, y_trainval)  # here we perform the bayes search\n",
    "\n",
    "print(\"\\n[Best parameters found:] \")\n",
    "print(bayes_svm.best_params_)\n",
    "print(f\"[Best MCC validation] {bayes_svm.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7962ad59-61af-459b-b028-87a879e22b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC on testing set (bayesian search): 0.27780167190974636\n"
     ]
    }
   ],
   "source": [
    "#predict the benchmark set\n",
    "pipeline_svm.set_params(**bayes_svm.best_params_).fit(x_trainval_svm, y_trainval) #parameters of BayesSearchCV\n",
    "bench_pred_svm = pipeline_svm.predict(x_bench_svm)\n",
    "#save the model\n",
    "with open(\"../models/svm_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(pipeline_svm, f)\n",
    "#compute the mcc\n",
    "mcc_bayes_svm = matthews_corrcoef(y_bench , bench_pred_svm)\n",
    "print(f\"MCC on testing set (bayesian search): {mcc_bayes_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef256401-0ea9-4ec1-b3bf-f3438d1c02f6",
   "metadata": {},
   "source": [
    "## 4. Linear Model Optimization (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4ff20f9-bd22-40d2-90e2-58732ffb449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Best parameters found:] \n",
      "OrderedDict({'lr__C': 46.788604247112445})\n",
      "[Best MCC validation] 0.2868\n"
     ]
    }
   ],
   "source": [
    "x_trainval_lr=x_trainval[features_to_use_lr]\n",
    "x_bench_lr=x_bench[features_to_use_lr]\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    (\"lr\", LogisticRegression(class_weight='balanced', max_iter=10000))\n",
    "])\n",
    "search_space_lr = {\n",
    "    \"lr__C\": Real(0.01, 1000, prior=\"log-uniform\"), \n",
    "}\n",
    "\n",
    "bayes_lr = BayesSearchCV(\n",
    "    estimator=pipeline_lr,\n",
    "    search_spaces=search_space_lr,\n",
    "    scoring=\"matthews_corrcoef\",   \n",
    "    n_jobs=-1,\n",
    "    refit=False,                 \n",
    "    random_state=42,\n",
    "    cv=5,\n",
    "    n_iter=100\n",
    ")\n",
    "bayes_lr.fit(x_trainval_lr, y_trainval)  # here we perform the bayes search\n",
    "\n",
    "print(\"\\n[Best parameters found:] \")\n",
    "print(bayes_lr.best_params_)\n",
    "print(f\"[Best MCC validation] {bayes_lr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b33024c-0306-4e52-80e1-cd12fd417627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC on testing set (bayesian search): 0.3122593945265407\n"
     ]
    }
   ],
   "source": [
    "#predict the benchmark set\n",
    "pipeline_lr.set_params(**bayes_lr.best_params_).fit(x_trainval_lr, y_trainval) #parameters of BayesSearchCV\n",
    "bench_pred_lr = pipeline_lr.predict(x_bench_lr)\n",
    "#save the model\n",
    "with open(\"../models/lr_model.pkl\", 'wb') as f:\n",
    "    pickle.dump(pipeline_lr, f)\n",
    "#compute the mcc\n",
    "mcc_bayes_lr = matthews_corrcoef(y_bench , bench_pred_lr)\n",
    "print(f\"MCC on testing set (bayesian search): {mcc_bayes_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11bf62-f017-4ce4-9a21-8a9829a09b3e",
   "metadata": {},
   "source": [
    "## 5. Final Inference and Artifact Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d843ea44-bcde-4e86-a04b-34698837322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions  saved in data/benchmark_prediction_lr.pkl, data/benchmark_prediction_svm.pkl and data/benchmark_prediction_tree.pkl for analysis part\n"
     ]
    }
   ],
   "source": [
    "output_path='../data/'\n",
    "joblib.dump(bench_pred_lr, os.path.join(output_path, 'benchmark_prediction_lr.pkl'))\n",
    "\n",
    "joblib.dump(bench_pred_svm, os.path.join(output_path, 'benchmark_prediction_svm.pkl'))\n",
    "\n",
    "joblib.dump(bench_pred_tree, os.path.join(output_path, 'benchmark_prediction_tree.pkl'))\n",
    "print(\"Predictions  saved in data/benchmark_prediction_lr.pkl, data/benchmark_prediction_svm.pkl and data/benchmark_prediction_tree.pkl for analysis part\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
