{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768cc93e-e13b-4aaf-aa7d-b096d704060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "#! pip install scikit-optimize\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import matthews_corrcoef , confusion_matrix, classification_report\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..', 'codes'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from confusion_matrix import plot_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc2db3f-fe17-440d-9848-a43d70179c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "features_to_use_tree = joblib.load('../data/best_features_list_tree.pkl')\n",
    "features_to_use_svm = joblib.load('../data/best_features_list_svm.pkl')\n",
    "features_to_use_lr = joblib.load('../data/best_features_list_lr.pkl')\n",
    "df=pd.read_csv(\"../data/data_refined_stratifkfold.csv\")\n",
    "x_trainval,y_trainval=df.query(\"Set=='1' or Set=='2' or Set=='3' or Set=='4' or Set=='5'\").drop(columns=['Set','Stage']),df.query(\"Set=='1' or Set=='2' or Set=='3' or Set=='4' or Set=='5'\")['Stage']\n",
    "x_bench,y_bench=df.query(\"Set=='Benchmark'\").drop(columns=['Set','Stage']),df.query(\"Set=='Benchmark'\")['Stage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc07caf-e7cf-4abc-8b16-5521be57143e",
   "metadata": {},
   "source": [
    "first of all we'll try some models.. to see which one is more efficient. First of all we'll try the balanced random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c14ead-d4ce-4372-b92b-be1ced3cd4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Best parameters found:] \n",
      "OrderedDict({'rf__max_depth': 27, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 5, 'rf__min_samples_split': 20, 'rf__n_estimators': 165})\n",
      "[Best MCC validation] 0.3138\n"
     ]
    }
   ],
   "source": [
    "x_trainval_tree=x_trainval[features_to_use_tree]\n",
    "x_bench_tree=x_bench[features_to_use_tree]\n",
    "pipeline_tree = Pipeline([(\"rf\", BalancedRandomForestClassifier(sampling_strategy='all', replacement=True, random_state=42, n_jobs=-1))])\n",
    "search_space_tree = {\n",
    "    \"rf__n_estimators\": Integer(100, 1000),      # Numero di alberi\n",
    "    \"rf__max_depth\": Integer(10, 100),           # Profondità massima (per evitare overfitting)\n",
    "    \"rf__min_samples_split\": Integer(2, 20),     # Minimo campioni per splittare\n",
    "    \"rf__min_samples_leaf\": Integer(1, 10),      # Minimo campioni in una foglia\n",
    "    \"rf__max_features\": Categorical(['sqrt', 'log2']) # Quante feature guardare ad ogni split\n",
    "}\n",
    "\n",
    "bayes_tree = BayesSearchCV(\n",
    "    estimator=pipeline_tree,\n",
    "    search_spaces=search_space_tree,\n",
    "    scoring=\"matthews_corrcoef\",   \n",
    "    n_jobs=-1,\n",
    "    refit=False,                 \n",
    "    random_state=42,\n",
    "    cv=5,\n",
    "    n_iter=60 # Puoi abbassare a 30-40 se è troppo lento\n",
    ")\n",
    "\n",
    "bayes_tree.fit(x_trainval_tree, y_trainval)\n",
    "\n",
    "print(\"\\n[Best parameters found:] \")\n",
    "print(bayes_tree.best_params_)\n",
    "print(f\"[Best MCC validation] {bayes_tree.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd73dae7-7e21-4016-ab9b-ea53a003d1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC on testing set (bayesian search): 0.2696759802769695\n"
     ]
    }
   ],
   "source": [
    "#predict the benchmark set\n",
    "pipeline_tree.set_params(**bayes_tree.best_params_).fit(x_trainval_tree, y_trainval) #parameters of BayesSearchCV\n",
    "bench_pred_tree = pipeline_tree.predict(x_bench_tree)\n",
    "#compute the mcc\n",
    "mcc_bayes_tree = matthews_corrcoef(y_bench , bench_pred_tree)\n",
    "print(f\"MCC on testing set (bayesian search): {mcc_bayes_tree}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91afd307-7503-486c-9e9e-b28766bae2a5",
   "metadata": {},
   "source": [
    "Now try with svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efa2737-81bb-45fc-a696-94655839b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Best parameters found:] \n",
      "OrderedDict({'svm__C': 4.216925736715804, 'svm__gamma': 0.007138140134113495, 'svm__kernel': 'rbf'})\n",
      "[Best MCC validation] 0.3051\n"
     ]
    }
   ],
   "source": [
    "x_trainval_svm=x_trainval[features_to_use_svm]\n",
    "x_bench_svm=x_bench[features_to_use_svm]\n",
    "\n",
    "pipeline_svm = Pipeline([(\"svm\" , SVC(cache_size=1500,class_weight='balanced'))])\n",
    "search_space_svm = {\n",
    "        \"svm__kernel\": Categorical([\"rbf\"]),\n",
    "        \"svm__C\": Real(0.01, 1000, prior=\"log-uniform\"),                \n",
    "        \"svm__gamma\": Real(1e-5, 100, prior=\"log-uniform\"), \n",
    "    }\n",
    "#set up the BayesSearch\n",
    "bayes_svm = BayesSearchCV(\n",
    "    estimator=pipeline_svm,\n",
    "    search_spaces=search_space_svm,\n",
    "    scoring=\"matthews_corrcoef\",   \n",
    "    n_jobs=-1,\n",
    "    refit=False,                 \n",
    "    random_state=42,\n",
    "    cv=5,\n",
    "    n_iter=60\n",
    ")\n",
    "bayes_svm.fit(x_trainval_svm, y_trainval)  # here we perform the bayes search\n",
    "\n",
    "print(\"\\n[Best parameters found:] \")\n",
    "print(bayes_svm.best_params_)\n",
    "print(f\"[Best MCC validation] {bayes_svm.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7962ad59-61af-459b-b028-87a879e22b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC on testing set (bayesian search): 0.23088939179313445\n"
     ]
    }
   ],
   "source": [
    "#predict the benchmark set\n",
    "pipeline_svm.set_params(**bayes_svm.best_params_).fit(x_trainval_svm, y_trainval) #parameters of BayesSearchCV\n",
    "bench_pred_svm = pipeline_svm.predict(x_bench_svm)\n",
    "#compute the mcc\n",
    "mcc_bayes_svm = matthews_corrcoef(y_bench , bench_pred_svm)\n",
    "print(f\"MCC on testing set (bayesian search): {mcc_bayes_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4ff20f9-bd22-40d2-90e2-58732ffb449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Best parameters found:] \n",
      "OrderedDict({'lr__C': 995.8663355212396})\n",
      "[Best MCC validation] 0.2902\n"
     ]
    }
   ],
   "source": [
    "x_trainval_lr=x_trainval[features_to_use_lr]\n",
    "x_bench_lr=x_bench[features_to_use_lr]\n",
    "\n",
    "pipeline_lr = Pipeline([\n",
    "    (\"lr\", LogisticRegression(class_weight='balanced', max_iter=10000))\n",
    "])\n",
    "search_space_lr = {\n",
    "    \"lr__C\": Real(0.01, 1000, prior=\"log-uniform\"), \n",
    "}\n",
    "\n",
    "bayes_lr = BayesSearchCV(\n",
    "    estimator=pipeline_lr,\n",
    "    search_spaces=search_space_lr,\n",
    "    scoring=\"matthews_corrcoef\",   \n",
    "    n_jobs=-1,\n",
    "    refit=False,                 \n",
    "    random_state=42,\n",
    "    cv=5,\n",
    "    n_iter=60\n",
    ")\n",
    "bayes_lr.fit(x_trainval_lr, y_trainval)  # here we perform the bayes search\n",
    "\n",
    "print(\"\\n[Best parameters found:] \")\n",
    "print(bayes_lr.best_params_)\n",
    "print(f\"[Best MCC validation] {bayes_lr.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b33024c-0306-4e52-80e1-cd12fd417627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC on testing set (bayesian search): 0.29762156839760645\n"
     ]
    }
   ],
   "source": [
    "#predict the benchmark set\n",
    "pipeline_lr.set_params(**bayes_lr.best_params_).fit(x_trainval_lr, y_trainval) #parameters of BayesSearchCV\n",
    "bench_pred_lr = pipeline_lr.predict(x_bench_lr)\n",
    "#compute the mcc\n",
    "mcc_bayes_lr = matthews_corrcoef(y_bench , bench_pred_lr)\n",
    "print(f\"MCC on testing set (bayesian search): {mcc_bayes_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acee4f43-3923-4809-acf4-b15be54a96c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification Report svm (Dettaglio per ogni classe) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.17      0.67      0.27         3\n",
      "         2.0       0.35      0.43      0.39        14\n",
      "         3.0       0.43      0.25      0.32        24\n",
      "         4.0       0.65      0.59      0.62        22\n",
      "\n",
      "    accuracy                           0.43        63\n",
      "   macro avg       0.40      0.48      0.40        63\n",
      "weighted avg       0.48      0.43      0.44        63\n",
      "\n",
      "\n",
      "--- Classification Report tree (Dettaglio per ogni classe) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.12      0.33      0.18         3\n",
      "         2.0       0.27      0.29      0.28        14\n",
      "         3.0       0.60      0.38      0.46        24\n",
      "         4.0       0.64      0.73      0.68        22\n",
      "\n",
      "    accuracy                           0.48        63\n",
      "   macro avg       0.41      0.43      0.40        63\n",
      "weighted avg       0.52      0.48      0.48        63\n",
      "\n",
      "\n",
      "--- Classification Report lr (Dettaglio per ogni classe) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.13      0.67      0.22         3\n",
      "         2.0       0.38      0.43      0.40        14\n",
      "         3.0       0.60      0.25      0.35        24\n",
      "         4.0       0.68      0.68      0.68        22\n",
      "\n",
      "    accuracy                           0.46        63\n",
      "   macro avg       0.45      0.51      0.41        63\n",
      "weighted avg       0.56      0.46      0.47        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- NUOVA PARTE: Recall per ogni stadio ---\n",
    "\n",
    "# Opzione 1: Report completo (consigliato, molto leggibile)\n",
    "print(\"\\n--- Classification Report svm (Dettaglio per ogni classe) ---\")\n",
    "print(classification_report(y_bench, bench_pred_svm))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Opzione 1: Report completo (consigliato, molto leggibile)\n",
    "print(\"\\n--- Classification Report tree (Dettaglio per ogni classe) ---\")\n",
    "print(classification_report(y_bench, bench_pred_tree))\n",
    "\n",
    "\n",
    "\n",
    "# Opzione 1: Report completo (consigliato, molto leggibile)\n",
    "print(\"\\n--- Classification Report lr (Dettaglio per ogni classe) ---\")\n",
    "print(classification_report(y_bench, bench_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58efad5-9efe-40e9-91e8-62997094b264",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_bench' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m plot_cm(\u001b[43my_bench\u001b[49m,bench_pred_lr,\u001b[33m'\u001b[39m\u001b[33mLogistic Regression\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGreens\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m plot_cm(y_bench,bench_pred_tree,\u001b[33m'\u001b[39m\u001b[33mBalanced Random Forest\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mOranges\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m plot_cm(y_bench,bench_pred_svm,\u001b[33m'\u001b[39m\u001b[33mSVM\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'y_bench' is not defined"
     ]
    }
   ],
   "source": [
    "plot_cm(y_bench,bench_pred_lr,'Logistic Regression', 'Greens', '../figures/03_cm_lr.svg')\n",
    "plot_cm(y_bench,bench_pred_tree,'Balanced Random Forest', 'Oranges','../figures/03_cm_tree.svg')\n",
    "plot_cm(y_bench,bench_pred_svm,'SVM','../figures/03_cm_svm.svg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
